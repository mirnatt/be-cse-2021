* <<<PE404>>> REINFORCEMENT LEARNING
:properties:
:author: Ms. M. Saritha and Ms. S. Rajalakshmi
:date: 15-03-2021
:end:

#+startup: showall
{{{credits}}}
|L|T|P|C|
|3|0|0|3|

** CO PO MAPPING :noexport:
#+NAME: co-po-mapping 

|                | PO1 | PO2 | PO3 | PO4 | PO5 | PO6 | PO7 | PO8 | PO9 | PO10 | PO11 | PO12 | PSO1 | PSO2 | PSO3 |
| CO1            |   2 |   3 |   3 |   3 |   0 |   0 |   0 |   0 |   0 |    1 |    0 |    2 |    3 |    1 |    1 |
| CO2            |   2 |   3 |   3 |   3 |   0 |   0 |   0 |   0 |   0 |    1 |    0 |    2 |    3 |    1 |    2 |
| CO3            |   2 |   3 |   3 |   3 |   0 |   0 |   0 |   0 |   0 |    1 |    0 |    2 |    3 |    1 |    2 |
| CO4            |   2 |   3 |   3 |   3 |   0 |   0 |   0 |   0 |   0 |    1 |    0 |    2 |    3 |    1 |    2 |
| CO5            |   2 |   3 |   3 |   3 |   0 |   0 |   0 |   0 |   0 |    1 |    0 |    2 |    3 |    1 |    2 |
| Score          |  10 |  15 |  15 |  15 |   0 |   0 |   0 |   0 |   0 |    5 |    0 |   10 |   15 |    5 |    9 |

#+begin_comment
| Course Mapping |   3 |   3 |   2 |   0 |   2 |   0 |   0 |   1 |   1 |    1 |    0 |    1 |    2 |    3 |    2 |
#+end_comment

** COURSE OBJECTIVES
- To understand the basics of reinforcement learning techniques
- To explore various methods used in reinforcement learning
- To apply reinforcement learning techniques for various case studies.

{{{unit}}}
| UNIT I | INTRODUCTION | 9 |
Reinforcement Learning -- Examples -- Elements of Reinforcement
Learning -- Limitations and Scope -- Tic-Tac-Toe; Multi-armed Bandits;
Finite Markov Decision Processes.

{{{unit}}}
| UNIT II | TABULAR SOLUTION METHODS | 11 |
Dynamic Programming; Monte Carlo Methods: Prediction -- Estimation of
Action Values -- Control -- Control without Exploring Starts --
Off-policy Prediction via Importance Sampling -- Incremental
Implementation -- Off-policy Monte Carlo Control; Temporal-Difference
Learning.

{{{unit}}}
| UNIT III |  INTEGRATION OF TABULAR METHODS | 9 |
n-step Bootstrapping: TD Prediction -- Sarsa -- Off-policy Learning;
Planning and Learning with Tabular Methods.

{{{unit}}}
| UNIT IV |   | APPROXIMATE SOLUTION METHODS | 10 |
On-policy Prediction with Approximation; On-policy Control with
Approximation; Eligibility Traces: The \lambda-return -- TD(\lambda)
-- n-step Truncated \lambda-return Methods -- Online \lambda-return
Algorithm -- True Online TD(\lambda); Policy Gradient Methods.

{{{unit}}}
| UNIT V | APPLICATIONS AND CASE STUDIES | 6 |
TD-Gammon; Watsonâ€™s Daily-Double Wagering; Optimizing Memory Control;
Human-level Video Game Play.

\hfill *Total Periods: 45*

** COURSE OUTCOMES
After the completion of this course, students will be able to: 
- Illustrate the basics of reinforcement learning problem (K2)
- Solve various problems using tabular solution methods (K3)
- Apply the integrated tabular methods for problem solutions (K3)
- Illustrate approximate solution methods for larger state space problems (K2)
- Apply reinforcement learning techniques for various case studies (K3).

** TEXT BOOKS
1. Richard S. Sutton & Andrew G. Barto, ``Reinforcement Learning: An Introduction'', The MIT Press, 2nd Edition, 2018.
2. Marco Wiering & Martijn van Otterlo, ``Reinforcement Learning State-of-the-Art'', Springer, 2012.

** REFERENCES
1.  Boris Belousov, Hany Abdulsamad, Pascal Klink, Simone Parisi & Jan Peters, ``Reinforcement Learning Algorithms: Analysis and Applications'', Springer, 1st edition, 2021. 
2.  Micheal Lanham, ``Hands-On Reinforcement Learning for Games'', Packt Publishing Ltd., 2020.
3.  Taweh Beysolow II, ``Applied Reinforcement Learning with Python'', Apress, 2019.
4.  Dimitri Bertsekas, ``Reinforcement Learning and Optimal Control'', Athena Scientific, 2019. 
